{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a GRU to Generate Human-like Mouse Trajectories\n",
    "\n",
    "This notebook:\n",
    "- Loads all `../data/session_*.jsonl` recordings.\n",
    "- Normalizes each trajectory: translate to (0,0), rotate so target is at angle 0, and scale so the target lies at x=1.\n",
    "- Resamples each path to a fixed length (e.g., 64 steps).\n",
    "- Trains a small GRU to predict next (x,y) given current (x,y) and normalized time `u`.\n",
    "- Generates 100 trajectories towards random canvas targets (750x550) and visualizes them.\n",
    "\n",
    "Requirements: `torch` (installed via `training/requirements.txt`). The repo `.venv` already has numpy/matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = (Path.cwd() / '..' / 'data').resolve()\n",
    "files = sorted(DATA_DIR.glob('session_*.jsonl'))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f'No session_*.jsonl in {DATA_DIR}. Collect data via web_capture first.')\n",
    "len(files), files[-3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities: normalization and resampling\n",
    "def to_arrays(path):\n",
    "    t = np.array([p['t'] for p in path], dtype=float)\n",
    "    x = np.array([p['x'] for p in path], dtype=float)\n",
    "    y = np.array([p['y'] for p in path], dtype=float)\n",
    "    t = t - t.min()\n",
    "    keep = np.r_[True, np.diff(t) > 0]\n",
    "    return t[keep], x[keep], y[keep]\n",
    "\n",
    "def normalize_to_target(t, x, y, target):\n",
    "    # translate so start at (0,0)\n",
    "    x0, y0 = x[0], y[0]\n",
    "    xt, yt = x - x0, y - y0\n",
    "    tx, ty = float(target.get('x', x0)) - x0, float(target.get('y', y0)) - y0\n",
    "    D = math.hypot(tx, ty)\n",
    "    if D == 0: D = 1.0\n",
    "    ang = math.atan2(ty, tx)\n",
    "    ca, sa = math.cos(-ang), math.sin(-ang)\n",
    "    xr = ca*xt - sa*yt\n",
    "    yr = sa*xt + ca*yt\n",
    "    xnorm, ynorm = xr / D, yr / D\n",
    "    return xnorm, ynorm, D, ang, (x0, y0)\n",
    "\n",
    "def resample_fixed(t, x, y, steps=64):\n",
    "    if len(t) < 2:\n",
    "        u = np.linspace(0,1,steps)\n",
    "        return u, np.zeros(steps), np.zeros(steps)\n",
    "    T = t[-1] - t[0]\n",
    "    if T <= 0: T = 1.0\n",
    "    u_raw = (t - t[0]) / T\n",
    "    u = np.linspace(0, 1, steps)\n",
    "    x_i = np.interp(u, u_raw, x)\n",
    "    y_i = np.interp(u, u_raw, y)\n",
    "    return u, x_i, y_i\n",
    "\n",
    "def inverse_transform(xn, yn, D, ang, origin):\n",
    "    # from normalized (target at 1,0) back to canvas\n",
    "    xr, yr = xn * D, yn * D\n",
    "    ca, sa = math.cos(ang), math.sin(ang)\n",
    "    x = ca*xr - sa*yr + origin[0]\n",
    "    y = sa*xr + ca*yr + origin[1]\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare dataset\n",
    "STEPS = 64\n",
    "samples = []  # each: dict with 'u', 'xy' (steps x 2)\n",
    "count_lines = 0\n",
    "for fp in files:\n",
    "    with open(fp, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            count_lines += 1\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            try:\n",
    "                rec = json.loads(line)\n",
    "            except Exception:\n",
    "                continue\n",
    "            path = rec.get('path', [])\n",
    "            if len(path) < 5: # too short\n",
    "                continue\n",
    "            t, x, y = to_arrays(path)\n",
    "            # basic sanity\n",
    "            if not np.isfinite([t,x,y]).all():\n",
    "                continue\n",
    "            u, xi, yi = resample_fixed(t, x, y, steps=STEPS)\n",
    "            xn, yn, D, ang, origin = normalize_to_target(t, xi, yi, rec.get('target', {}))\n",
    "            if np.isnan(xn).any() or np.isnan(yn).any():\n",
    "                continue\n",
    "            xy = np.stack([xn, yn], axis=1)\n",
    "            samples.append({'u': u.astype(np.float32), 'xy': xy.astype(np.float32)})\n",
    "len(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch Dataset\n",
    "class TrajDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        u = s['u']   # (S,)\n",
    "        xy = s['xy'] # (S,2)\n",
    "        # inputs are first S-1 steps; targets are next S-1 steps\n",
    "        inp = np.concatenate([xy[:-1], u[:-1,None]], axis=1)  # (S-1, 3)\n",
    "        tgt = xy[1:]  # (S-1, 2)\n",
    "        return torch.from_numpy(inp), torch.from_numpy(tgt)\n",
    "\n",
    "ds = TrajDataset(samples)\n",
    "n_train = int(0.9*len(ds))\n",
    "n_val = len(ds) - n_train\n",
    "train_ds, val_ds = torch.utils.data.random_split(ds, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "len(train_ds), len(val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 128\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH, shuffle=False, drop_last=False)\n",
    "next(iter(train_loader))[0].shape, next(iter(train_loader))[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: GRU that maps (x,y,u) -> next (x,y)\n",
    "class TrajGRU(nn.Module):\n",
    "    def __init__(self, input_size=3, hidden=128, layers=2):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden, num_layers=layers, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "    def forward(self, x, h=None):\n",
    "        # x: (B, T, 3)\n",
    "        y, h = self.gru(x, h)\n",
    "        out = self.head(y)\n",
    "        return out, h\n",
    "\n",
    "model = TrajGRU().to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit = nn.MSELoss()\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop\n",
    "EPOCHS = 20\n",
    "train_hist, val_hist = [], []\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train(); tl=0.0; nb=0\n",
    "    for inp, tgt in train_loader:\n",
    "        inp = inp.to(DEVICE).float()\n",
    "        tgt = tgt.to(DEVICE).float()\n",
    "        opt.zero_grad()\n",
    "        pred, _ = model(inp)  # (B, T, 2)\n",
    "        loss = crit(pred, tgt)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        tl += loss.item(); nb += 1\n",
    "    train_loss = tl / max(1, nb)\n",
    "    # val\n",
    "    model.eval(); vl=0.0; vb=0\n",
    "    with torch.no_grad():\n",
    "        for inp, tgt in val_loader:\n",
    "            inp = inp.to(DEVICE).float()\n",
    "            tgt = tgt.to(DEVICE).float()\n",
    "            pred, _ = model(inp)\n",
    "            loss = crit(pred, tgt)\n",
    "            vl += loss.item(); vb += 1\n",
    "    val_loss = vl / max(1, vb)\n",
    "    train_hist.append(train_loss); val_hist.append(val_loss)\n",
    "    print(f'Epoch {epoch:02d}  train {train_loss:.4f}  val {val_loss:.4f}')\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(train_hist, label='train')\n",
    "plt.plot(val_hist, label='val')\n",
    "plt.xlabel('epoch'); plt.ylabel('MSE'); plt.legend(); plt.title('Training curve')\n",
   "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoints to training/checkpoints/\n",
    "from pathlib import Path\n",
    "ROOT = Path.cwd()\n",
    "TRAIN_DIR = ROOT / 'training' if (ROOT / 'training').exists() else ROOT\n",
    "CKPT_DIR = TRAIN_DIR / 'checkpoints'\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "last_path = CKPT_DIR / 'last.pt'\n",
    "torch.save({'model': model.state_dict()}, last_path)\n",
    "print(f'Saved last checkpoint to {last_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: load a checkpoint before generation (set LOAD accordingly)\n",
    "from pathlib import Path\n",
    "LOAD = 'last'  # 'last', 'best', a file path, or None to skip\n",
    "ROOT = Path.cwd()\n",
    "TRAIN_DIR = ROOT / 'training' if (ROOT / 'training').exists() else ROOT\n",
    "CKPT_DIR = TRAIN_DIR / 'checkpoints'\n",
    "if LOAD in ('last', 'best'):\n",
    "    path = CKPT_DIR / f'{LOAD}.pt'\n",
    "elif LOAD:\n",
    "    path = Path(LOAD)\n",
    "else:\n",
    "    path = None\n",
    "if path and path.exists():\n",
    "    state = torch.load(path, map_location=DEVICE)\n",
    "    model.load_state_dict(state['model'])\n",
    "    print(f'Loaded checkpoint from {path}')\n",
    "else:\n",
    "    print('No checkpoint loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation: sample 100 random targets on 750x550 canvas\n",
    "CANVAS_W, CANVAS_H = 750, 550\n",
    "RADIUS = 12\n",
    "MARGIN = RADIUS + 10\n",
    "def sample_start_target():\n",
    "    sx = np.random.randint(MARGIN, CANVAS_W - MARGIN)\n",
    "    sy = np.random.randint(MARGIN, CANVAS_H - MARGIN)\n",
    "    # ensure target is not too close to start\n",
    "    for _ in range(100):\n",
    "        tx = np.random.randint(MARGIN, CANVAS_W - MARGIN)\n",
    "        ty = np.random.randint(MARGIN, CANVAS_H - MARGIN)\n",
    "        if (tx-sx)**2 + (ty-sy)**2 >= (5*RADIUS)**2:\n",
    "            return (sx, sy), (tx, ty)\n",
    "    return (sx, sy), (tx, ty)\n",
    "\n",
    "def generate_norm(model, steps=STEPS):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # start at (0,0), roll forward\n",
    "        xn = np.zeros((steps,), dtype=np.float32)\n",
    "        yn = np.zeros((steps,), dtype=np.float32)\n",
    "        u = np.linspace(0, 1, steps, dtype=np.float32)\n",
    "        h = None\n",
    "        for i in range(steps-1):\n",
    "            inp = torch.tensor([[ [xn[i], yn[i], u[i]] ]], dtype=torch.float32, device=DEVICE)  # (1,1,3)\n",
    "            out, h = model(inp, h)  # (1,1,2)\n",
    "            xn[i+1], yn[i+1] = out[0,0].cpu().numpy()\n",
    "        return u, xn, yn\n",
    "\n",
    "# Generate 100\n",
    "trajectories = []\n",
    "for _ in range(100):\n",
    "    (sx, sy), (tx, ty) = sample_start_target()\n",
    "    u, xn, yn = generate_norm(model, steps=STEPS)\n",
    "    D = math.hypot(tx-sx, ty-sy)\n",
    "    ang = math.atan2(ty-sy, tx-sx)\n",
    "    x, y = inverse_transform(xn, yn, D, ang, (sx, sy))\n",
    "    trajectories.append((x, y, (sx, sy), (tx, ty)))\n",
    "len(trajectories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize generated trajectories\n",
    "plt.figure(figsize=(8,6))\n",
    "for (x, y, (sx, sy), (tx, ty)) in trajectories:\n",
    "    plt.plot(x, y, color='tab:purple', alpha=0.2, lw=1.8)\n",
    "# draw a few sampled targets\n",
    "for i in range(0, len(trajectories), max(1, len(trajectories)//10)):\n",
    "    _, _, (sx, sy), (tx, ty) = trajectories[i]\n",
    "    plt.scatter([sx, tx], [sy, ty], s=12, c=['#22c55e','#ef4444'])\n",
    "plt.xlim(0, CANVAS_W); plt.ylim(0, CANVAS_H)\n",
    "plt.gca().invert_yaxis()  # canvas y-down convention\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.title('Generated trajectories to random targets (purple)')\n",
    "plt.xlabel('x (px)'); plt.ylabel('y (px)')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
